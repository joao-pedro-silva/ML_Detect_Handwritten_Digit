{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mnist = tf.keras.datasets.mnist # Dataset of 28x28 images of hand-written digits 0-9\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data() # Unpack dataset into training and testing variables\n",
    "x_train = tf.keras.utils.normalize(x_train, axis=1) # normalise data (scaling)\n",
    "x_test = tf.keras.utils.normalize(x_test, axis=1) # normalise data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.08216044 0.2286589  0.3728098\n",
      "  0.30506548 0.08583808 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.08087653 0.38341541 0.36240278 0.37133624\n",
      "  0.48350001 0.4068725  0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.08861609 0.3824786  0.40758025 0.36240278 0.35218\n",
      "  0.44704564 0.43262392 0.06832372 0.00859123 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.01621743\n",
      "  0.095788   0.36759266 0.42460179 0.40758025 0.36240278 0.29765841\n",
      "  0.16116667 0.43262392 0.30326141 0.17468832 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.26434406\n",
      "  0.4023096  0.41354174 0.42460179 0.40758025 0.36240278 0.37133624\n",
      "  0.18419048 0.32446794 0.30326141 0.23912253 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.08411834 0.38597476\n",
      "  0.40390606 0.41518278 0.32013627 0.18365276 0.36384089 0.33597088\n",
      "  0.09017659 0.13562417 0.30565873 0.2405544  0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.07427511 0.39255225 0.40867916\n",
      "  0.4023096  0.29374592 0.02021913 0.12082418 0.17401086 0.03094469\n",
      "  0.         0.         0.30326141 0.34794476 0.12263192 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.04890249 0.2553207  0.41729294 0.37786605\n",
      "  0.33206506 0.13784725 0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.40468535 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.00966301 0.22906954 0.38994434 0.39585101 0.11514373\n",
      "  0.03033287 0.04594908 0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.07868449 0.32430069 0.38994434 0.10391089 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.47826451 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.27332506 0.3255876  0.29400565 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30565873 0.36226348 0.48071715 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.33960736 0.33958568 0.32430069 0.17330859 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.30326141 0.36083161 0.3629905  0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.29598873 0.03868495 0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.01343056 0.23176282 0.30326141 0.26632809 0.02943166 0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.28698037 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.0103149\n",
      "  0.25134326 0.43262392 0.26969888 0.10166287 0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.18660159 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.0690291  0.24313682\n",
      "  0.48350001 0.29699976 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.38429254 0.34924869 0.28955419 0.         0.         0.\n",
      "  0.         0.         0.         0.18365276 0.34226929 0.3728098\n",
      "  0.31082143 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.32043997 0.22592013 0.0791702  0.04703054\n",
      "  0.13569967 0.29210488 0.37910874 0.40758025 0.3206977  0.24608394\n",
      "  0.10744445 0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.37982402 0.34786826 0.32430069 0.38994434 0.37770784 0.34867468\n",
      "  0.4023096  0.41354174 0.42460179 0.31575387 0.18695382 0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.1251185  0.27470549 0.32430069 0.38994434 0.41729294 0.40867916\n",
      "  0.4023096  0.38236201 0.24431452 0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.03451074 0.16472416 0.38994434 0.41729294 0.40867916\n",
      "  0.2251018  0.06071843 0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]\n",
      " [0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(x_train[1]) # Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1fe29d6c288>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[1], cmap = plt.cm.binary) # Display on sample from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural Network Model\n",
    "model = tf.keras.models.Sequential()\n",
    "model.add(tf.keras.layers.Flatten()) # Input Layer\n",
    "model.add(tf.keras.layers.Dense(64, activation = tf.nn.relu)) # Two dense layer\n",
    "model.add(tf.keras.layers.Dense(64, activation = tf.nn.relu)) # Two dense layer\n",
    "model.add(tf.keras.layers.Dense(10, activation = tf.nn.softmax)) # Output Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer= 'adam',\n",
    "             loss= 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 51000 samples, validate on 9000 samples\n",
      "Epoch 1/10\n",
      "51000/51000 [==============================] - 5s 89us/sample - loss: 0.3245 - accuracy: 0.9058 - val_loss: 0.1723 - val_accuracy: 0.9501\n",
      "Epoch 2/10\n",
      "51000/51000 [==============================] - 4s 72us/sample - loss: 0.1452 - accuracy: 0.9560 - val_loss: 0.1269 - val_accuracy: 0.9623\n",
      "Epoch 3/10\n",
      "51000/51000 [==============================] - 4s 73us/sample - loss: 0.1042 - accuracy: 0.9684 - val_loss: 0.1098 - val_accuracy: 0.9651\n",
      "Epoch 4/10\n",
      "51000/51000 [==============================] - 4s 74us/sample - loss: 0.0824 - accuracy: 0.9743 - val_loss: 0.1104 - val_accuracy: 0.9672\n",
      "Epoch 5/10\n",
      "51000/51000 [==============================] - 4s 73us/sample - loss: 0.0658 - accuracy: 0.9791 - val_loss: 0.1021 - val_accuracy: 0.9701\n",
      "Epoch 6/10\n",
      "51000/51000 [==============================] - 4s 78us/sample - loss: 0.0545 - accuracy: 0.9824 - val_loss: 0.1064 - val_accuracy: 0.9683\n",
      "Epoch 7/10\n",
      "51000/51000 [==============================] - 4s 75us/sample - loss: 0.0438 - accuracy: 0.9855 - val_loss: 0.1083 - val_accuracy: 0.9704\n",
      "Epoch 8/10\n",
      "51000/51000 [==============================] - 4s 73us/sample - loss: 0.0378 - accuracy: 0.9874 - val_loss: 0.1037 - val_accuracy: 0.9727\n",
      "Epoch 9/10\n",
      "51000/51000 [==============================] - 4s 73us/sample - loss: 0.0301 - accuracy: 0.9900 - val_loss: 0.1095 - val_accuracy: 0.9742\n",
      "Epoch 10/10\n",
      "51000/51000 [==============================] - 4s 75us/sample - loss: 0.0270 - accuracy: 0.9908 - val_loss: 0.1212 - val_accuracy: 0.9716\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train, batch_size=25, epochs=10, validation_split=0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
